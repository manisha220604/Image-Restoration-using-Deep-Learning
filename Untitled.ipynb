{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "344f128f-4d1a-4c38-86b5-726e17aa6f13",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '\\\\mnt\\\\data\\\\Complete_Art_Restoration_Project.ipynb'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 134\u001b[39m\n\u001b[32m    132\u001b[39m \u001b[38;5;66;03m# Save notebook\u001b[39;00m\n\u001b[32m    133\u001b[39m nb[\u001b[33m'\u001b[39m\u001b[33mcells\u001b[39m\u001b[33m'\u001b[39m] = cells\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnotebook_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mw\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    135\u001b[39m     nbf.write(nb, f)\n\u001b[32m    137\u001b[39m notebook_path.name\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py:326\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    321\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    322\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    323\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    324\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '\\\\mnt\\\\data\\\\Complete_Art_Restoration_Project.ipynb'"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import nbformat as nbf\n",
    "\n",
    "# Define notebook path\n",
    "notebook_path = Path(\"/mnt/data/Complete_Art_Restoration_Project.ipynb\")\n",
    "\n",
    "# Create a new notebook\n",
    "nb = nbf.v4.new_notebook()\n",
    "cells = []\n",
    "\n",
    "# Title\n",
    "cells.append(nbf.v4.new_markdown_cell(\"# Complete Art Restoration Project using Deep Learning\\n\"\n",
    "\"Restore damaged artwork images using a U-Net based deep learning model.\"))\n",
    "\n",
    "# Install requirements\n",
    "cells.append(nbf.v4.new_code_cell(\"\"\"\n",
    "!pip install -q opencv-python tensorflow keras matplotlib kaggle\n",
    "\"\"\"))\n",
    "\n",
    "# Import libraries\n",
    "cells.append(nbf.v4.new_code_cell(\"\"\"\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\"\"\"))\n",
    "\n",
    "# Set up Kaggle API and download dataset\n",
    "cells.append(nbf.v4.new_markdown_cell(\"## Step 1: Download and Extract Dataset\"))\n",
    "cells.append(nbf.v4.new_code_cell(\"\"\"\n",
    "# Upload kaggle.json before running this\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "# Download a dataset of artwork (example: paintings)\n",
    "!kaggle datasets download -d andrewmvd/art-painting-images\n",
    "!unzip -q art-painting-images.zip -d paintings_dataset\n",
    "\"\"\"))\n",
    "\n",
    "# Function to add synthetic damage\n",
    "cells.append(nbf.v4.new_markdown_cell(\"## Step 2: Define Damage Simulation\"))\n",
    "cells.append(nbf.v4.new_code_cell(\"\"\"\n",
    "def add_damage(image):\n",
    "    damaged = image.copy()\n",
    "    noise = np.random.normal(0, 25, image.shape).astype(np.uint8)\n",
    "    damaged = cv2.add(damaged, noise)\n",
    "    h, w, _ = image.shape\n",
    "    damaged[h//4:h//3, w//4:w//2] = 255  # white patch\n",
    "    return damaged\n",
    "\"\"\"))\n",
    "\n",
    "# Data preparation\n",
    "cells.append(nbf.v4.new_markdown_cell(\"## Step 3: Preprocess and Prepare Dataset\"))\n",
    "cells.append(nbf.v4.new_code_cell(\"\"\"\n",
    "image_paths = glob(\"paintings_dataset/*/*.jpg\")\n",
    "images = []\n",
    "damaged_images = []\n",
    "for path in image_paths[:500]:  # Use first 500 for quick training\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.resize(img, (128, 128))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    images.append(img / 255.0)\n",
    "    damaged_images.append(add_damage(img) / 255.0)\n",
    "\n",
    "images = np.array(images)\n",
    "damaged_images = np.array(damaged_images)\n",
    "x_train, x_val, y_train, y_val = train_test_split(damaged_images, images, test_size=0.2)\n",
    "\"\"\"))\n",
    "\n",
    "# Build U-Net model\n",
    "cells.append(nbf.v4.new_markdown_cell(\"## Step 4: Build U-Net Model\"))\n",
    "cells.append(nbf.v4.new_code_cell(\"\"\"\n",
    "def build_unet(input_shape=(128, 128, 3)):\n",
    "    inputs = Input(input_shape)\n",
    "    c1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    p1 = MaxPooling2D()(c1)\n",
    "    c2 = Conv2D(128, 3, activation='relu', padding='same')(p1)\n",
    "    p2 = MaxPooling2D()(c2)\n",
    "    b = Conv2D(256, 3, activation='relu', padding='same')(p2)\n",
    "    u1 = UpSampling2D()(b)\n",
    "    m1 = concatenate([u1, c2])\n",
    "    c3 = Conv2D(128, 3, activation='relu', padding='same')(m1)\n",
    "    u2 = UpSampling2D()(c3)\n",
    "    m2 = concatenate([u2, c1])\n",
    "    c4 = Conv2D(64, 3, activation='relu', padding='same')(m2)\n",
    "    outputs = Conv2D(3, 1, activation='sigmoid')(c4)\n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "model = build_unet()\n",
    "model.compile(optimizer=Adam(1e-4), loss='mse', metrics=['mae'])\n",
    "model.summary()\n",
    "\"\"\"))\n",
    "\n",
    "# Train model\n",
    "cells.append(nbf.v4.new_markdown_cell(\"## Step 5: Train the Model\"))\n",
    "cells.append(nbf.v4.new_code_cell(\"\"\"\n",
    "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=20, batch_size=16)\n",
    "model.save(\"art_restoration_model.h5\")\n",
    "\"\"\"))\n",
    "\n",
    "# Visualize predictions\n",
    "cells.append(nbf.v4.new_markdown_cell(\"## Step 6: Test and Visualize Results\"))\n",
    "cells.append(nbf.v4.new_code_cell(\"\"\"\n",
    "sample = x_val[0]\n",
    "predicted = model.predict(np.expand_dims(sample, axis=0))[0]\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,3,1)\n",
    "plt.title(\"Damaged\")\n",
    "plt.imshow(sample)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.title(\"Restored\")\n",
    "plt.imshow(predicted)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.title(\"Original\")\n",
    "plt.imshow(y_val[0])\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\"\"\"))\n",
    "\n",
    "# Save notebook\n",
    "nb['cells'] = cells\n",
    "with open(notebook_path, 'w') as f:\n",
    "    nbf.write(nb, f)\n",
    "\n",
    "notebook_path.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b9f1c47-9db2-45d3-9d83-e8b5a7cd285a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Complete_Art_Restoration_Project.ipynb'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import nbformat as nbf\n",
    "\n",
    "# Define notebook path\n",
    "notebook_path = Path(\"/mnt/data/Complete_Art_Restoration_Project.ipynb\")\n",
    "\n",
    "# âœ… Ensure the directory exists\n",
    "notebook_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create a new notebook\n",
    "nb = nbf.v4.new_notebook()\n",
    "cells = []\n",
    "\n",
    "# Title\n",
    "cells.append(nbf.v4.new_markdown_cell(\"# Complete Art Restoration Project using Deep Learning\\n\"\n",
    "\"Restore damaged artwork images using a U-Net based deep learning model.\"))\n",
    "\n",
    "# Install requirements\n",
    "cells.append(nbf.v4.new_code_cell(\"\"\"\n",
    "!pip install -q opencv-python tensorflow keras matplotlib kaggle\n",
    "\"\"\"))\n",
    "\n",
    "# Import libraries\n",
    "cells.append(nbf.v4.new_code_cell(\"\"\"\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\"\"\"))\n",
    "\n",
    "# Set up Kaggle API and download dataset\n",
    "cells.append(nbf.v4.new_markdown_cell(\"## Step 1: Download and Extract Dataset\"))\n",
    "cells.append(nbf.v4.new_code_cell(\"\"\"\n",
    "# Upload kaggle.json before running this\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "# Download a dataset of artwork (example: paintings)\n",
    "!kaggle datasets download -d andrewmvd/art-painting-images\n",
    "!unzip -q art-painting-images.zip -d paintings_dataset\n",
    "\"\"\"))\n",
    "\n",
    "# Function to add synthetic damage\n",
    "cells.append(nbf.v4.new_markdown_cell(\"## Step 2: Define Damage Simulation\"))\n",
    "cells.append(nbf.v4.new_code_cell(\"\"\"\n",
    "def add_damage(image):\n",
    "    damaged = image.copy()\n",
    "    noise = np.random.normal(0, 25, image.shape).astype(np.uint8)\n",
    "    damaged = cv2.add(damaged, noise)\n",
    "    h, w, _ = image.shape\n",
    "    damaged[h//4:h//3, w//4:w//2] = 255  # white patch\n",
    "    return damaged\n",
    "\"\"\"))\n",
    "\n",
    "# Data preparation\n",
    "cells.append(nbf.v4.new_markdown_cell(\"## Step 3: Preprocess and Prepare Dataset\"))\n",
    "cells.append(nbf.v4.new_code_cell(\"\"\"\n",
    "image_paths = glob(\"paintings_dataset/*/*.jpg\")\n",
    "images = []\n",
    "damaged_images = []\n",
    "for path in image_paths[:500]:  # Use first 500 for quick training\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.resize(img, (128, 128))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    images.append(img / 255.0)\n",
    "    damaged_images.append(add_damage(img) / 255.0)\n",
    "\n",
    "images = np.array(images)\n",
    "damaged_images = np.array(damaged_images)\n",
    "x_train, x_val, y_train, y_val = train_test_split(damaged_images, images, test_size=0.2)\n",
    "\"\"\"))\n",
    "\n",
    "# Build U-Net model\n",
    "cells.append(nbf.v4.new_markdown_cell(\"## Step 4: Build U-Net Model\"))\n",
    "cells.append(nbf.v4.new_code_cell(\"\"\"\n",
    "def build_unet(input_shape=(128, 128, 3)):\n",
    "    inputs = Input(input_shape)\n",
    "    c1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    p1 = MaxPooling2D()(c1)\n",
    "    c2 = Conv2D(128, 3, activation='relu', padding='same')(p1)\n",
    "    p2 = MaxPooling2D()(c2)\n",
    "    b = Conv2D(256, 3, activation='relu', padding='same')(p2)\n",
    "    u1 = UpSampling2D()(b)\n",
    "    m1 = concatenate([u1, c2])\n",
    "    c3 = Conv2D(128, 3, activation='relu', padding='same')(m1)\n",
    "    u2 = UpSampling2D()(c3)\n",
    "    m2 = concatenate([u2, c1])\n",
    "    c4 = Conv2D(64, 3, activation='relu', padding='same')(m2)\n",
    "    outputs = Conv2D(3, 1, activation='sigmoid')(c4)\n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "model = build_unet()\n",
    "model.compile(optimizer=Adam(1e-4), loss='mse', metrics=['mae'])\n",
    "model.summary()\n",
    "\"\"\"))\n",
    "\n",
    "# Train model\n",
    "cells.append(nbf.v4.new_markdown_cell(\"## Step 5: Train the Model\"))\n",
    "cells.append(nbf.v4.new_code_cell(\"\"\"\n",
    "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=20, batch_size=16)\n",
    "model.save(\"art_restoration_model.h5\")\n",
    "\"\"\"))\n",
    "\n",
    "# Visualize predictions\n",
    "cells.append(nbf.v4.new_markdown_cell(\"## Step 6: Test and Visualize Results\"))\n",
    "cells.append(nbf.v4.new_code_cell(\"\"\"\n",
    "sample = x_val[0]\n",
    "predicted = model.predict(np.expand_dims(sample, axis=0))[0]\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,3,1)\n",
    "plt.title(\"Damaged\")\n",
    "plt.imshow(sample)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.title(\"Restored\")\n",
    "plt.imshow(predicted)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.title(\"Original\")\n",
    "plt.imshow(y_val[0])\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\"\"\"))\n",
    "\n",
    "# Save notebook\n",
    "nb['cells'] = cells\n",
    "with open(notebook_path, 'w') as f:\n",
    "    nbf.write(nb, f)\n",
    "\n",
    "notebook_path.name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba74b846-c862-4b3c-a729-80c0edbf7cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='/mnt/data/Complete_Art_Restoration_Project.ipynb' target='_blank'>/mnt/data/Complete_Art_Restoration_Project.ipynb</a><br>"
      ],
      "text/plain": [
       "C:\\mnt\\data\\Complete_Art_Restoration_Project.ipynb"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "\n",
    "FileLink('/mnt/data/Complete_Art_Restoration_Project.ipynb')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb687bc7-b2ae-442b-9b27-a950c70b4e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='Complete_Art_Restoration_Project.ipynb' target='_blank'>Complete_Art_Restoration_Project.ipynb</a><br>"
      ],
      "text/plain": [
       "C:\\Users\\manis\\OneDrive\\Desktop\\jupyter projects\\Complete_Art_Restoration_Project.ipynb"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save to current directory instead of /mnt/data/\n",
    "notebook_path = Path(\"Complete_Art_Restoration_Project.ipynb\")\n",
    "notebook_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "nb['cells'] = cells\n",
    "with open(notebook_path, 'w') as f:\n",
    "    nbf.write(nb, f)\n",
    "\n",
    "from IPython.display import FileLink\n",
    "FileLink(notebook_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48cd556-5578-4f2a-aa41-15882b548a1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
